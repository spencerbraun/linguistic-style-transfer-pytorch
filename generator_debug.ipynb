{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from linguistic_style_transfer_pytorch.config import GeneralConfig, ModelConfig\n",
    "from linguistic_style_transfer_pytorch.data_loader import TextDataset\n",
    "from linguistic_style_transfer_pytorch.model import AdversarialVAE\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "#%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "gconfig = GeneralConfig()\n",
    "config = GeneralConfig()\n",
    "mconfig = ModelConfig()\n",
    "\n",
    "# load word embeddings\n",
    "weights = torch.FloatTensor(np.load(gconfig.word_embedding_path))\n",
    "# load checkpoint\n",
    "model_checkpoint = torch.load('linguistic_style_transfer_pytorch/checkpoints/model_epoch_20.pt')\n",
    "# Load model\n",
    "model = AdversarialVAE(weight=weights)\n",
    "model.load_state_dict(model_checkpoint)\n",
    "model.eval()\n",
    "\n",
    "# Load average style embeddings\n",
    "with open(config.avg_style_emb_path, 'rb') as f:\n",
    "    avg_style_embeddings = pickle.load(f)\n",
    "# set avg_style_emb attribute of the model\n",
    "model.avg_style_emb = avg_style_embeddings\n",
    "# load word2index\n",
    "with open(gconfig.w2i_file_path) as f:\n",
    "    word2index = json.load(f)\n",
    "# load index2word\n",
    "with open(gconfig.i2w_file_path) as f:\n",
    "    index2word = json.load(f)\n",
    "label2index = {'neg': 0, 'pos': 1}\n",
    "# Read input sentence\n",
    "source_sentence = \"this soup is good\"#input(\"Enter the source sentence\")\n",
    "target_style = \"neg\"#input(\"Enter the target style: pos or neg\")\n",
    "# Get token ids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "token_ids = [word2index.get(word, gconfig.unk_token)\n",
    "             for word in source_sentence.split()]\n",
    "token_ids = torch.LongTensor(token_ids)\n",
    "target_style_id = torch.LongTensor(label2index[target_style])\n",
    "# Get transfered sentence token ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z = torch.FloatTensor([[1,2,3,4,5,6,7,8]]).view([8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z.repeat(128).view([128,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "torch.from_numpy(np.array([4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "torch.LongTensor([0, 1]) == torch.tensor([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "torch.tensor([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_dataset = TextDataset(mode='test')\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=mconfig.batch_size)\n",
    "for iteration, batch in enumerate(tqdm(test_dataloader)):\n",
    "    \n",
    "    # unpacking\n",
    "    sequences, seq_lens, labels, bow_rep = batch\n",
    "    print(sequences.shape, seq_lens.shape)\n",
    "    model.transfer_style(sequences, seq_lens.view([128]), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rnn = torch.nn.RNN(10, 20, 2, batch_first=True)\n",
    "input_ = torch.autograd.Variable(torch.randn(5, 3, 10).transpose(0, 1))\n",
    "h0 = torch.autograd.Variable(torch.randn(2, 3, 20))\n",
    "# output, hn = rnn(input, h0)\n",
    "input_.size(), h0.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mconfig.embedding_size + mconfig.generative_emb_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mconfig.hidden_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "target_tokenids = model.transfer_style(token_ids, target_style_id)\n",
    "target_sentence = \"\".join([index2word.get(idx) for idx in target_tokenids])\n",
    "print(\"Style transfered sentence: {}\".format(target_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from linguistic_style_transfer_pytorch.config import GeneralConfig, ModelConfig\n",
    "from linguistic_style_transfer_pytorch.data_loader import TextDataset\n",
    "from linguistic_style_transfer_pytorch.model import AdversarialVAE\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading for generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gconfig = GeneralConfig()\n",
    "config = GeneralConfig()\n",
    "mconfig = ModelConfig()\n",
    "\n",
    "# load word embeddings\n",
    "weights = torch.FloatTensor(np.load(gconfig.word_embedding_path))\n",
    "# load checkpoint\n",
    "model_checkpoint = torch.load('linguistic_style_transfer_pytorch/checkpoints/model_epoch_10.pt')\n",
    "# Load model\n",
    "model = AdversarialVAE(weight=weights)\n",
    "model.load_state_dict(model_checkpoint)\n",
    "model.eval()\n",
    "\n",
    "# Load average style embeddings\n",
    "with open(config.avg_style_emb_path, 'rb') as f:\n",
    "    avg_style_embeddings = pickle.load(f)\n",
    "# set avg_style_emb attribute of the model\n",
    "model.avg_style_emb = avg_style_embeddings\n",
    "# load word2index\n",
    "with open(gconfig.w2i_file_path) as f:\n",
    "    word2index = json.load(f)\n",
    "# load index2word\n",
    "with open(gconfig.i2w_file_path) as f:\n",
    "    index2word = json.load(f)\n",
    "label2index = {'neg': 0, 'pos': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "if use_cuda:\n",
    "    model = model.to(\"cuda\")\n",
    "\n",
    "#=============== Define dataloader ================#\n",
    "test_dataset = TextDataset(mode='train')\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=mconfig.batch_size)\n",
    "content_discriminator_params, style_discriminator_params, vae_and_classifier_params = model.get_params()\n",
    "#model.transfer_style(sequences, seq_lens.view([128]), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sequences, seq_lens, labels, bow_rep = [x for x in test_dataloader][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_lengths = seq_lens.view([128])\n",
    "seq_lens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 40])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model.transfer_style(self, sequences, seq_lengths, style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seq_lengths, perm_index = seq_lengths.sort(descending=True)\n",
    "sequences = sequences[perm_index]\n",
    "print(sequences.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([39, 38, 36, 35, 35, 34, 34, 34, 34, 34, 34, 34, 33, 33, 33, 32, 32, 31,\n",
      "        30, 30, 30, 29, 28, 28, 28, 27, 27, 27, 26, 26, 26, 25, 25, 25, 24, 24,\n",
      "        24, 23, 23, 23, 23, 23, 23, 23, 22, 21, 21, 21, 20, 20, 19, 19, 19, 18,\n",
      "        18, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 16, 16, 16, 16, 16, 16, 15,\n",
      "        15, 15, 15, 15, 15, 15, 15, 14, 14, 14, 13, 13, 13, 12, 12, 12, 12, 12,\n",
      "        12, 12, 12, 12, 12, 12, 12, 12, 11, 11, 11, 11, 11, 11, 11, 11, 11, 10,\n",
      "        10, 10, 10, 10, 10, 10,  9,  9,  9,  9,  9,  9,  9,  9,  8,  8,  8,  7,\n",
      "         7,  6])\n"
     ]
    }
   ],
   "source": [
    "print(seq_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 40, 300])\n"
     ]
    }
   ],
   "source": [
    "embedded_seqs = model.embedding(sequences)\n",
    "print(embedded_seqs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 39, 512])\n"
     ]
    }
   ],
   "source": [
    "#seq_lengths = torch.from_numpy(np.array([15]))\n",
    "packed_seqs = pack_padded_sequence(\n",
    "    embedded_seqs, lengths=seq_lengths, batch_first=True)\n",
    "packed_output, (_) = model.encoder(packed_seqs)\n",
    "output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 512])\n",
      "torch.Size([128, 128])\n"
     ]
    }
   ],
   "source": [
    "sentence_emb = output[torch.arange(output.size(0)), seq_lengths-1]\n",
    "print(sentence_emb.shape)\n",
    "\n",
    "content_emb_mu, content_emb_log_var = model.get_content_emb(\n",
    "    sentence_emb)\n",
    "print(content_emb_mu.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 128])\n"
     ]
    }
   ],
   "source": [
    "sampled_content_emb = model.sample_prior(\n",
    "    content_emb_mu, content_emb_log_var)\n",
    "print(sampled_content_emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 8])\n"
     ]
    }
   ],
   "source": [
    "target_style_emb = model.avg_style_emb[1].repeat(128).view([128,8])\n",
    "print(target_style_emb.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generative_emb = torch.cat(\n",
    "    (target_style_emb, sampled_content_emb), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 136])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generative_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8261, -1.6626, -2.1619,  ...,  1.1458, -0.9463,  0.2676],\n",
       "        [-0.8261, -1.6626, -2.1619,  ...,  0.9806, -0.8630,  0.3588],\n",
       "        [-0.8261, -1.6626, -2.1619,  ...,  1.0237, -0.9309,  0.2863],\n",
       "        ...,\n",
       "        [-0.8261, -1.6626, -2.1619,  ...,  1.2252, -0.9657,  0.2883],\n",
       "        [-0.8261, -1.6626, -2.1619,  ...,  1.1768, -1.0424,  0.3253],\n",
       "        [-0.8261, -1.6626, -2.1619,  ...,  0.8604, -0.8106,  0.4840]],\n",
       "       grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generative_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### self.generate_sentences(self, input_sentences, latent_emb, inference=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transfered_sentence = self.generate_sentences(\n",
    "#     input_sentences=None, latent_emb=generative_emb, inference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_sentences = sequences\n",
    "latent_emb=generative_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 40])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 136])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sos_token_tensor = torch.tensor(\n",
    "        [gconfig.predefined_word_index['<sos>']], \n",
    "        device=input_sentences.device).unsqueeze(0).repeat(mconfig.batch_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sos_token_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_sentences = torch.cat(\n",
    "        (sos_token_tensor, input_sentences), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 40])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence_embs = model.embedding(input_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 40, 300])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# latent_emb = latent_emb.unsqueeze(1).repeat(\n",
    "#         1, mconfig.max_seq_len+1, 1)\n",
    "latent_emb = latent_emb.unsqueeze(1).repeat(\n",
    "        1, mconfig.max_seq_len, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 136])\n",
      "torch.Size([128, 40, 136])\n"
     ]
    }
   ],
   "source": [
    "print(generative_emb.shape)\n",
    "print(latent_emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen_sent_embs = torch.cat(\n",
    "        (sentence_embs, latent_emb), dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 40, 436])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_sent_embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output_sentences = torch.zeros(\n",
    "#     mconfig.max_seq_len, mconfig.batch_size, \n",
    "#     device=input_sentences.device)\n",
    "output_sentences = torch.zeros(\n",
    "        mconfig.max_seq_len, mconfig.batch_size, mconfig.vocab_size, device=input_sentences.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 128, 9203])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n"
     ]
    }
   ],
   "source": [
    "hidden_states = torch.zeros(\n",
    "        mconfig.batch_size, mconfig.hidden_dim, device=input_sentences.device)\n",
    "print(mconfig.hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 256])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mconfig.max_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for idx in range(mconfig.max_seq_len):\n",
    "    # get words at the index idx from all the batches\n",
    "    words = gen_sent_embs[:, idx, :]\n",
    "    hidden_states = model.decoder(words, hidden_states)\n",
    "    # project over vocab space\n",
    "    next_word_logits = model.projector(hidden_states)\n",
    "#     next_word = nn.Softmax(dim=1)(next_word_logits).argmax(dim=1)\n",
    "    output_sentences[idx] = next_word_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 3, 3,  ..., 3, 3, 3],\n",
       "        [3, 3, 3,  ..., 3, 3, 3],\n",
       "        [3, 3, 3,  ..., 3, 3, 3],\n",
       "        ...,\n",
       "        [3, 3, 3,  ..., 3, 3, 3],\n",
       "        [3, 3, 3,  ..., 3, 3, 3],\n",
       "        [3, 3, 3,  ..., 3, 3, 3]])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sentences.argmax(dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 40])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss(ignore_index=0)\n",
    "recon_loss = loss(\n",
    "    output_sentences.view(-1, mconfig.vocab_size), input_sentences.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5120, 9203])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sentences.view(-1, mconfig.vocab_size).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9203])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_word_logits[0,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 9203])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_word_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "next_word_probs = nn.Softmax(dim=1)(self.projector(hidden_states))\n",
    "next_word = max(next_word_probs.argmax(1))\n",
    "output_sentence[idx] = next_word\n",
    "word_emb = self.embedding(next_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model.encoder(output_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 9203])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_word_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 128, 9203])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training mode\n",
    "if not inference:\n",
    "    # Prepend the input sentences with <sos> token\n",
    "    sos_token_tensor = torch.tensor(\n",
    "        [gconfig.predefined_word_index['<sos>']], \n",
    "        device=input_sentences.device).unsqueeze(0).repeat(mconfig.batch_size, 1)\n",
    "    input_sentences = torch.cat(\n",
    "        (sos_token_tensor, input_sentences), dim=1)\n",
    "    sentence_embs = self.dropout(self.embedding(input_sentences))\n",
    "    # Make the latent embedding compatible for concatenation\n",
    "    # by repeating it for max_seq_len + 1(additional one bcoz <sos> tokens were added)\n",
    "    latent_emb = latent_emb.unsqueeze(1).repeat(\n",
    "        1, mconfig.max_seq_len+1, 1)\n",
    "    gen_sent_embs = torch.cat(\n",
    "        (sentence_embs, latent_emb), dim=2)\n",
    "    # Delete latent embedding and sos token tensor to reduce memory usage\n",
    "    del latent_emb, sos_token_tensor\n",
    "    output_sentences = torch.zeros(\n",
    "        mconfig.max_seq_len, mconfig.batch_size, mconfig.vocab_size, device=input_sentences.device)\n",
    "    # initialize hidden state\n",
    "    hidden_states = torch.zeros(\n",
    "        mconfig.batch_size, mconfig.hidden_dim, device=input_sentences.device)\n",
    "    # generate sentences one word at a time in a loop\n",
    "    for idx in range(mconfig.max_seq_len):\n",
    "        # get words at the index idx from all the batches\n",
    "        words = gen_sent_embs[:, idx, :]\n",
    "        hidden_states = self.decoder(words, hidden_states)\n",
    "        # project over vocab space\n",
    "        next_word_logits = self.projector(hidden_states)\n",
    "        output_sentences[idx] = next_word_logits\n",
    "# if inference mode is on\n",
    "else:\n",
    "\n",
    "    sos_token_tensor = torch.tensor(\n",
    "        [gconfig.predefined_word_index['<sos>']], device=latent_emb.device).unsqueeze(0).repeat(mconfig.batch_size, 1)\n",
    "    word_emb = self.embedding(sos_token_tensor)\n",
    "    hidden_states = torch.zeros(\n",
    "        mconfig.batch_size, mconfig.hidden_dim, device=latent_emb.device)\n",
    "    # Store output sentences\n",
    "    output_sentences = torch.zeros(\n",
    "        mconfig.max_seq_len, 1, device=latent_emb.device)\n",
    "    latent_emb = latent_emb.unsqueeze(1)#.repeat(\n",
    "        #1, mconfig.max_seq_len+1, 1)\n",
    "    with torch.no_grad():\n",
    "        # Greedily generate new words at a time\n",
    "        for idx in range(mconfig.max_seq_len):\n",
    "            gen_sent_embs = torch.cat(\n",
    "                (word_emb, latent_emb), dim=2)\n",
    "            words = gen_sent_embs[:, idx, :]\n",
    "            hidden_states = self.decoder(words, hidden_states)\n",
    "            next_word_probs = nn.Softmax(dim=1)(\n",
    "                self.projector(hidden_states))\n",
    "            next_word = max(next_word_probs.argmax(1))\n",
    "            output_sentence[idx] = next_word\n",
    "            word_emb = self.embedding(next_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
