{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from linguistic_style_transfer_pytorch.config import GeneralConfig, ModelConfig\n",
    "from linguistic_style_transfer_pytorch.data_loader import TextDataset\n",
    "from linguistic_style_transfer_pytorch.model import AdversarialVAE\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "# %load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "gconfig = GeneralConfig()\n",
    "config = GeneralConfig()\n",
    "mconfig = ModelConfig()\n",
    "\n",
    "# load word embeddings\n",
    "weights = torch.FloatTensor(np.load(gconfig.word_embedding_path))\n",
    "# load checkpoint\n",
    "model_checkpoint = torch.load('linguistic_style_transfer_pytorch/checkpoints/model_epoch_20.pt')\n",
    "# Load model\n",
    "model = AdversarialVAE(weight=weights)\n",
    "model.load_state_dict(model_checkpoint)\n",
    "model.eval()\n",
    "\n",
    "# Load average style embeddings\n",
    "with open(config.avg_style_emb_path, 'rb') as f:\n",
    "    avg_style_embeddings = pickle.load(f)\n",
    "# set avg_style_emb attribute of the model\n",
    "model.avg_style_emb = avg_style_embeddings\n",
    "# load word2index\n",
    "with open(gconfig.w2i_file_path) as f:\n",
    "    word2index = json.load(f)\n",
    "# load index2word\n",
    "with open(gconfig.i2w_file_path) as f:\n",
    "    index2word = json.load(f)\n",
    "label2index = {'neg': 0, 'pos': 1}\n",
    "# Read input sentence\n",
    "source_sentence = \"this soup is good\"#input(\"Enter the source sentence\")\n",
    "target_style = \"neg\"#input(\"Enter the target style: pos or neg\")\n",
    "# Get token ids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "token_ids = [word2index.get(word, gconfig.unk_token)\n",
    "             for word in source_sentence.split()]\n",
    "token_ids = torch.LongTensor(token_ids)\n",
    "target_style_id = torch.LongTensor(label2index[target_style])\n",
    "# Get transfered sentence token ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z = torch.FloatTensor([[1,2,3,4,5,6,7,8]]).view([8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.,  ..., 6., 7., 8.],\n",
       "        [1., 2., 3.,  ..., 6., 7., 8.],\n",
       "        [1., 2., 3.,  ..., 6., 7., 8.],\n",
       "        ...,\n",
       "        [1., 2., 3.,  ..., 6., 7., 8.],\n",
       "        [1., 2., 3.,  ..., 6., 7., 8.],\n",
       "        [1., 2., 3.,  ..., 6., 7., 8.]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.repeat(128).view([128,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(np.array([4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.LongTensor([0, 1]) == torch.tensor([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 15]) torch.Size([128, 1])\n",
      "torch.Size([128, 15, 300])\n",
      "torch.Size([128, 14, 512])\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128, 8])\n",
      "> \u001b[0;32m/Users/spencerbraun/Documents/Stanford/CS 230 - Deep Learning/Project/linguistic-style-transfer-pytorch/linguistic_style_transfer_pytorch/model.py\u001b[0m(465)\u001b[0;36mgenerate_sentences\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    464 \u001b[0;31m            \u001b[0;32mimport\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 465 \u001b[0;31m            sos_token_tensor = torch.LongTensor(\n",
      "\u001b[0m\u001b[0;32m    466 \u001b[0;31m                [gconfig.predefined_word_index['<sos>']], device=latent_emb.device).unsqueeze(0).repeat(mconfig.batch_size, 1)\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/spencerbraun/Documents/Stanford/CS 230 - Deep Learning/Project/linguistic-style-transfer-pytorch/linguistic_style_transfer_pytorch/model.py\u001b[0m(466)\u001b[0;36mgenerate_sentences\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    465 \u001b[0;31m            sos_token_tensor = torch.LongTensor(\n",
      "\u001b[0m\u001b[0;32m--> 466 \u001b[0;31m                [gconfig.predefined_word_index['<sos>']], device=latent_emb.device).unsqueeze(0).repeat(mconfig.batch_size, 1)\n",
      "\u001b[0m\u001b[0;32m    467 \u001b[0;31m            \u001b[0mword_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msos_token_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/spencerbraun/Documents/Stanford/CS 230 - Deep Learning/Project/linguistic-style-transfer-pytorch/linguistic_style_transfer_pytorch/model.py\u001b[0m(467)\u001b[0;36mgenerate_sentences\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    466 \u001b[0;31m                [gconfig.predefined_word_index['<sos>']], device=latent_emb.device).unsqueeze(0).repeat(mconfig.batch_size, 1)\n",
      "\u001b[0m\u001b[0;32m--> 467 \u001b[0;31m            \u001b[0mword_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msos_token_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    468 \u001b[0;31m            hidden_states = torch.zeros(\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/spencerbraun/Documents/Stanford/CS 230 - Deep Learning/Project/linguistic-style-transfer-pytorch/linguistic_style_transfer_pytorch/model.py\u001b[0m(468)\u001b[0;36mgenerate_sentences\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    467 \u001b[0;31m            \u001b[0mword_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msos_token_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 468 \u001b[0;31m            hidden_states = torch.zeros(\n",
      "\u001b[0m\u001b[0;32m    469 \u001b[0;31m                mconfig.batch_size, mconfig.hidden_dim, device=latent_emb.device)\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/spencerbraun/Documents/Stanford/CS 230 - Deep Learning/Project/linguistic-style-transfer-pytorch/linguistic_style_transfer_pytorch/model.py\u001b[0m(469)\u001b[0;36mgenerate_sentences\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    468 \u001b[0;31m            hidden_states = torch.zeros(\n",
      "\u001b[0m\u001b[0;32m--> 469 \u001b[0;31m                mconfig.batch_size, mconfig.hidden_dim, device=latent_emb.device)\n",
      "\u001b[0m\u001b[0;32m    470 \u001b[0;31m            \u001b[0;31m# Store output sentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/spencerbraun/Documents/Stanford/CS 230 - Deep Learning/Project/linguistic-style-transfer-pytorch/linguistic_style_transfer_pytorch/model.py\u001b[0m(471)\u001b[0;36mgenerate_sentences\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    470 \u001b[0;31m            \u001b[0;31m# Store output sentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 471 \u001b[0;31m            output_sentence = torch.zeros(\n",
      "\u001b[0m\u001b[0;32m    472 \u001b[0;31m                mconfig.max_seq_len, 1, device=latent_emb.device)\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/spencerbraun/Documents/Stanford/CS 230 - Deep Learning/Project/linguistic-style-transfer-pytorch/linguistic_style_transfer_pytorch/model.py\u001b[0m(472)\u001b[0;36mgenerate_sentences\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    471 \u001b[0;31m            output_sentence = torch.zeros(\n",
      "\u001b[0m\u001b[0;32m--> 472 \u001b[0;31m                mconfig.max_seq_len, 1, device=latent_emb.device)\n",
      "\u001b[0m\u001b[0;32m    473 \u001b[0;31m            \u001b[0mlatent_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlatent_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.repeat(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/spencerbraun/Documents/Stanford/CS 230 - Deep Learning/Project/linguistic-style-transfer-pytorch/linguistic_style_transfer_pytorch/model.py\u001b[0m(473)\u001b[0;36mgenerate_sentences\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    472 \u001b[0;31m                mconfig.max_seq_len, 1, device=latent_emb.device)\n",
      "\u001b[0m\u001b[0;32m--> 473 \u001b[0;31m            \u001b[0mlatent_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlatent_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.repeat(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    474 \u001b[0;31m                \u001b[0;31m#1, mconfig.max_seq_len+1, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/spencerbraun/Documents/Stanford/CS 230 - Deep Learning/Project/linguistic-style-transfer-pytorch/linguistic_style_transfer_pytorch/model.py\u001b[0m(475)\u001b[0;36mgenerate_sentences\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    474 \u001b[0;31m                \u001b[0;31m#1, mconfig.max_seq_len+1, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 475 \u001b[0;31m            \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    476 \u001b[0;31m                \u001b[0;31m# Greedily generate new words at a time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/spencerbraun/Documents/Stanford/CS 230 - Deep Learning/Project/linguistic-style-transfer-pytorch/linguistic_style_transfer_pytorch/model.py\u001b[0m(477)\u001b[0;36mgenerate_sentences\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    476 \u001b[0;31m                \u001b[0;31m# Greedily generate new words at a time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 477 \u001b[0;31m                \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_seq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    478 \u001b[0;31m                    gen_sent_embs = torch.cat(\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/spencerbraun/Documents/Stanford/CS 230 - Deep Learning/Project/linguistic-style-transfer-pytorch/linguistic_style_transfer_pytorch/model.py\u001b[0m(478)\u001b[0;36mgenerate_sentences\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    477 \u001b[0;31m                \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_seq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 478 \u001b[0;31m                    gen_sent_embs = torch.cat(\n",
      "\u001b[0m\u001b[0;32m    479 \u001b[0;31m                        (word_emb, latent_emb), dim=2)\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/spencerbraun/Documents/Stanford/CS 230 - Deep Learning/Project/linguistic-style-transfer-pytorch/linguistic_style_transfer_pytorch/model.py\u001b[0m(479)\u001b[0;36mgenerate_sentences\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    478 \u001b[0;31m                    gen_sent_embs = torch.cat(\n",
      "\u001b[0m\u001b[0;32m--> 479 \u001b[0;31m                        (word_emb, latent_emb), dim=2)\n",
      "\u001b[0m\u001b[0;32m    480 \u001b[0;31m                    \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_sent_embs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/spencerbraun/Documents/Stanford/CS 230 - Deep Learning/Project/linguistic-style-transfer-pytorch/linguistic_style_transfer_pytorch/model.py\u001b[0m(480)\u001b[0;36mgenerate_sentences\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    479 \u001b[0;31m                        (word_emb, latent_emb), dim=2)\n",
      "\u001b[0m\u001b[0;32m--> 480 \u001b[0;31m                    \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_sent_embs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    481 \u001b[0;31m                    \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/spencerbraun/Documents/Stanford/CS 230 - Deep Learning/Project/linguistic-style-transfer-pytorch/linguistic_style_transfer_pytorch/model.py\u001b[0m(481)\u001b[0;36mgenerate_sentences\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    480 \u001b[0;31m                    \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_sent_embs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 481 \u001b[0;31m                    \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    482 \u001b[0;31m                    next_word_probs = nn.Softmax(dim=1)(\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/spencerbraun/Documents/Stanford/CS 230 - Deep Learning/Project/linguistic-style-transfer-pytorch/linguistic_style_transfer_pytorch/model.py\u001b[0m(482)\u001b[0;36mgenerate_sentences\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    481 \u001b[0;31m                    \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 482 \u001b[0;31m                    next_word_probs = nn.Softmax(dim=1)(\n",
      "\u001b[0m\u001b[0;32m    483 \u001b[0;31m                        self.projector(hidden_states))\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/spencerbraun/Documents/Stanford/CS 230 - Deep Learning/Project/linguistic-style-transfer-pytorch/linguistic_style_transfer_pytorch/model.py\u001b[0m(483)\u001b[0;36mgenerate_sentences\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    482 \u001b[0;31m                    next_word_probs = nn.Softmax(dim=1)(\n",
      "\u001b[0m\u001b[0;32m--> 483 \u001b[0;31m                        self.projector(hidden_states))\n",
      "\u001b[0m\u001b[0;32m    484 \u001b[0;31m                    \u001b[0mnext_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_word_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/spencerbraun/Documents/Stanford/CS 230 - Deep Learning/Project/linguistic-style-transfer-pytorch/linguistic_style_transfer_pytorch/model.py\u001b[0m(484)\u001b[0;36mgenerate_sentences\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    483 \u001b[0;31m                        self.projector(hidden_states))\n",
      "\u001b[0m\u001b[0;32m--> 484 \u001b[0;31m                    \u001b[0mnext_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_word_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    485 \u001b[0;31m                    \u001b[0moutput_sentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/spencerbraun/Documents/Stanford/CS 230 - Deep Learning/Project/linguistic-style-transfer-pytorch/linguistic_style_transfer_pytorch/model.py\u001b[0m(485)\u001b[0;36mgenerate_sentences\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    484 \u001b[0;31m                    \u001b[0mnext_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_word_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 485 \u001b[0;31m                    \u001b[0moutput_sentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    486 \u001b[0;31m                    \u001b[0mword_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/spencerbraun/Documents/Stanford/CS 230 - Deep Learning/Project/linguistic-style-transfer-pytorch/linguistic_style_transfer_pytorch/model.py\u001b[0m(486)\u001b[0;36mgenerate_sentences\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    485 \u001b[0;31m                    \u001b[0moutput_sentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 486 \u001b[0;31m                    \u001b[0mword_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    487 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/spencerbraun/Documents/Stanford/CS 230 - Deep Learning/Project/linguistic-style-transfer-pytorch/linguistic_style_transfer_pytorch/model.py\u001b[0m(477)\u001b[0;36mgenerate_sentences\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    476 \u001b[0;31m                \u001b[0;31m# Greedily generate new words at a time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 477 \u001b[0;31m                \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_seq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    478 \u001b[0;31m                    gen_sent_embs = torch.cat(\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/spencerbraun/Documents/Stanford/CS 230 - Deep Learning/Project/linguistic-style-transfer-pytorch/linguistic_style_transfer_pytorch/model.py\u001b[0m(478)\u001b[0;36mgenerate_sentences\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    477 \u001b[0;31m                \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_seq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 478 \u001b[0;31m                    gen_sent_embs = torch.cat(\n",
      "\u001b[0m\u001b[0;32m    479 \u001b[0;31m                        (word_emb, latent_emb), dim=2)\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/spencerbraun/Documents/Stanford/CS 230 - Deep Learning/Project/linguistic-style-transfer-pytorch/linguistic_style_transfer_pytorch/model.py\u001b[0m(479)\u001b[0;36mgenerate_sentences\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    478 \u001b[0;31m                    gen_sent_embs = torch.cat(\n",
      "\u001b[0m\u001b[0;32m--> 479 \u001b[0;31m                        (word_emb, latent_emb), dim=2)\n",
      "\u001b[0m\u001b[0;32m    480 \u001b[0;31m                    \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_sent_embs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "IndexError: Dimension out of range (expected to be in range of [-1, 0], but got 2)\n",
      "> \u001b[0;32m/Users/spencerbraun/Documents/Stanford/CS 230 - Deep Learning/Project/linguistic-style-transfer-pytorch/linguistic_style_transfer_pytorch/model.py\u001b[0m(479)\u001b[0;36mgenerate_sentences\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    478 \u001b[0;31m                    gen_sent_embs = torch.cat(\n",
      "\u001b[0m\u001b[0;32m--> 479 \u001b[0;31m                        (word_emb, latent_emb), dim=2)\n",
      "\u001b[0m\u001b[0;32m    480 \u001b[0;31m                    \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_sent_embs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> word_emb.shape\n",
      "torch.Size([300])\n",
      "ipdb> latent_emb.shape\n",
      "torch.Size([128, 1, 136])\n",
      "ipdb> self.embedding(next_word)\n",
      "tensor([-1.1252e-01, -4.0276e-02,  2.9638e-01,  7.9783e-01, -7.6947e-01,\n",
      "        -3.8075e-02,  1.1904e-01,  6.5353e-01, -5.1388e-01,  5.8905e-01,\n",
      "        -7.9101e-01, -1.8619e-01,  2.6490e-01, -2.0671e-01, -4.9154e-01,\n",
      "        -1.6561e-01, -2.1957e-01, -4.4139e-01, -3.6978e-03,  7.9654e-01,\n",
      "        -6.0088e-01, -6.7927e-01, -1.7547e-01,  1.8162e-01, -5.7022e-01,\n",
      "         7.4841e-01, -4.8652e-01,  2.1329e-01, -5.9183e-01,  4.4286e-01,\n",
      "         1.1188e-01, -6.2554e-01, -1.3922e-01,  8.0589e-01,  1.9540e-01,\n",
      "         7.6227e-01,  2.6744e-01,  5.2242e-01, -9.5391e-02,  2.4589e-01,\n",
      "        -9.3315e-01, -1.3697e-01,  6.0192e-01,  6.7171e-01, -2.9551e-01,\n",
      "         4.5073e-01, -9.0097e-01, -1.4831e+00, -7.3542e-01, -3.9251e-01,\n",
      "         4.7987e-01,  7.7283e-02,  1.5703e+00, -2.2272e-01, -1.2722e-01,\n",
      "         3.0915e-01,  7.5214e-01, -9.0611e-01,  3.3125e-01, -2.0187e-01,\n",
      "        -1.0634e+00,  4.8999e-03, -4.5737e-02,  9.7196e-02, -5.0838e-01,\n",
      "        -4.0868e-01,  6.7565e-01, -3.9309e-01, -9.2747e-02,  2.7582e-01,\n",
      "        -4.2453e-01,  2.2281e-01,  5.8214e-01,  2.6033e-01,  1.6927e-01,\n",
      "        -6.7104e-01,  2.7036e-01, -2.7923e-01,  6.8698e-01,  5.4318e-01,\n",
      "        -1.1117e-01, -6.5161e-01,  5.3264e-02,  7.8215e-01,  7.7711e-02,\n",
      "         4.5258e-01, -1.5073e-01,  4.3699e-01,  2.0780e-01, -1.2138e+00,\n",
      "         4.3216e-01,  8.4871e-01, -7.7561e-02,  7.2354e-01,  1.0222e-01,\n",
      "        -2.7769e-01,  5.7271e-02, -4.1930e-02, -3.7468e-01, -1.5846e-01,\n",
      "         3.7997e-01, -1.3133e-01, -1.8171e-01, -5.2057e-02,  2.2489e-01,\n",
      "         3.3009e-01,  5.5554e-02, -3.5896e-01, -1.0395e+00,  5.3365e-01,\n",
      "         9.7846e-02, -2.0243e-01,  2.1633e-01,  3.8089e-01, -3.7586e-01,\n",
      "        -5.6782e-01,  1.0585e+00,  2.7836e-01,  1.7519e-01,  2.5515e-01,\n",
      "         6.4151e-01, -6.1760e-01, -7.7251e-01,  1.2679e+00,  6.8339e-02,\n",
      "         7.4753e-02, -5.8617e-02, -2.7300e-01,  8.5675e-01, -1.1919e-01,\n",
      "         4.3536e-01,  4.0224e-01,  8.1318e-01,  2.1910e-01, -1.0839e-01,\n",
      "         2.1510e-01,  5.0281e-01, -7.5473e-02, -1.8934e-01, -1.3289e+00,\n",
      "         4.3856e-01, -1.9479e-01, -2.0445e-01, -6.5268e-01, -6.5950e-01,\n",
      "        -2.5586e-01, -1.3176e-01,  1.2549e-01,  1.4283e-01, -1.6955e-01,\n",
      "        -3.1908e-01, -2.6274e-01,  1.2692e-01,  3.4099e-01, -4.1266e-01,\n",
      "         3.3583e-01, -5.8588e-01, -8.9819e-02, -8.1098e-01,  6.7104e-02,\n",
      "         1.9212e+00,  5.0980e-01,  1.7788e-01,  1.2218e-01, -4.4394e-01,\n",
      "        -4.1011e-01,  1.7133e-01, -2.7818e-01,  5.8193e-01, -8.7197e-01,\n",
      "        -8.0722e-01, -5.6560e-01, -1.7381e-01,  4.1924e-01,  1.7726e-01,\n",
      "        -2.1482e-01,  1.7057e-01, -2.1039e-01,  2.7790e-01,  3.3810e-01,\n",
      "         2.6594e-01, -2.6487e-01, -8.2112e-01,  4.9013e-01, -1.2115e-01,\n",
      "         6.6653e-02, -1.9731e-01, -3.8516e-01, -5.1757e-02, -8.7584e-01,\n",
      "        -6.4407e-01, -8.5985e-01, -1.2219e-01, -2.3890e-01, -3.3744e-01,\n",
      "        -8.7397e-01, -3.7071e-01, -2.1199e-01, -5.1139e-01, -1.2789e+00,\n",
      "         4.1386e-04, -4.6711e-01,  3.4117e-02,  5.8355e-01, -5.3668e-01,\n",
      "        -4.9037e-01, -4.9225e-02,  7.7929e-01,  3.2542e-01, -3.0605e-01,\n",
      "        -1.6901e-01, -3.5470e-01,  1.0347e-01,  7.0970e-01, -4.9102e-01,\n",
      "        -3.6697e-01,  3.7793e-01, -1.9217e-01,  8.8952e-01, -7.6254e-02,\n",
      "        -1.0574e+00, -4.9354e-01, -5.5555e-01,  6.8897e-02,  3.4731e-01,\n",
      "        -2.6213e-01,  1.0517e-01, -5.8797e-01,  7.6285e-02, -3.3486e-01,\n",
      "        -1.7943e-02,  1.4361e-01,  2.6591e-01, -3.6724e-01, -1.2148e-01,\n",
      "        -5.7602e-01,  3.8129e-01, -5.3362e-01,  1.2548e+00, -9.7834e-02,\n",
      "        -3.1445e-01,  1.3121e-01,  6.5640e-01,  5.7863e-01,  9.7079e-01,\n",
      "         1.2819e-01,  3.5610e-01,  3.3977e-01, -4.1231e-01,  1.7131e-01,\n",
      "         4.8397e-01, -7.3536e-02,  6.5855e-02, -1.5028e-01,  6.0344e-02,\n",
      "        -1.2528e+00,  6.6472e-02, -7.1731e-01,  1.0931e+00,  2.1347e-01,\n",
      "         1.2465e-01, -1.5174e-01, -7.6224e-01, -4.2146e-01,  8.5861e-01,\n",
      "        -3.1570e-01, -6.6434e-01, -8.6404e-01,  1.7756e+00,  6.7849e-02,\n",
      "        -1.4377e-02, -9.6594e-01,  6.1997e-02, -4.9088e-02,  1.1802e+00,\n",
      "        -3.7329e-01,  4.1056e-02, -7.3312e-01, -4.9225e-01, -9.7417e-02,\n",
      "        -7.8145e-01,  5.1675e-01,  2.1525e-01, -2.3176e-01,  6.9246e-01,\n",
      "        -1.9196e-01, -3.1089e-01,  3.4050e-02, -6.5689e-01,  1.0559e-01,\n",
      "        -2.1244e-01, -3.5117e-01,  3.8003e-01,  3.6715e-01, -6.3094e-01,\n",
      "        -5.4845e-01, -3.3476e-01, -3.2793e-01, -1.1686e+00, -8.8909e-01])\n",
      "ipdb> self.embedding(next_word).shape\n",
      "torch.Size([300])\n",
      "ipdb> exit\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-fb6d0e27d17d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_lens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbow_rep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_lens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransfer_style\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_lens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Stanford/CS 230 - Deep Learning/Project/linguistic-style-transfer-pytorch/linguistic_style_transfer_pytorch/model.py\u001b[0m in \u001b[0;36mtransfer_style\u001b[0;34m(self, sequences, seq_lengths, style)\u001b[0m\n\u001b[1;32m    549\u001b[0m         transfered_sentence = self.generate_sentences(\n\u001b[1;32m    550\u001b[0m             input_sentences=None, latent_emb=generative_emb, inference=True)\n\u001b[0;32m--> 551\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtransfered_sentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Stanford/CS 230 - Deep Learning/Project/linguistic-style-transfer-pytorch/linguistic_style_transfer_pytorch/model.py\u001b[0m in \u001b[0;36mgenerate_sentences\u001b[0;34m(self, input_sentences, latent_emb, inference)\u001b[0m\n\u001b[1;32m    477\u001b[0m                     gen_sent_embs = torch.cat(\n\u001b[1;32m    478\u001b[0m                         (word_emb, latent_emb), dim=2)\n\u001b[0;32m--> 479\u001b[0;31m                     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_sent_embs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m                     \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m                     next_word_probs = nn.Softmax(dim=1)(\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'exception'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c_call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mdispatch_exception\u001b[0;34m(self, frame, arg)\u001b[0m\n\u001b[1;32m    172\u001b[0m                     and arg[0] is StopIteration and arg[2] is None):\n\u001b[1;32m    173\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0;31m# Stop at the StopIteration or GeneratorExit exception when the user\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;31m# has set stopframe in a generator by issuing a return command, or a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_dataset = TextDataset(mode='test')\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=mconfig.batch_size)\n",
    "for iteration, batch in enumerate(tqdm(test_dataloader)):\n",
    "    \n",
    "    # unpacking\n",
    "    sequences, seq_lens, labels, bow_rep = batch\n",
    "    print(sequences.shape, seq_lens.shape)\n",
    "    model.transfer_style(sequences, seq_lens.view([128]), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 5, 10]), torch.Size([2, 3, 20]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = torch.nn.RNN(10, 20, 2, batch_first=True)\n",
    "input_ = torch.autograd.Variable(torch.randn(5, 3, 10).transpose(0, 1))\n",
    "h0 = torch.autograd.Variable(torch.randn(2, 3, 20))\n",
    "# output, hn = rnn(input, h0)\n",
    "input_.size(), h0.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "436"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mconfig.embedding_size + mconfig.generative_emb_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mconfig.hidden_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "target_tokenids = model.transfer_style(token_ids, target_style_id)\n",
    "target_sentence = \"\".join([index2word.get(idx) for idx in target_tokenids])\n",
    "print(\"Style transfered sentence: {}\".format(target_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/20 [00:00<?, ?it/s]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█▎        | 1/8 [00:00<00:03,  2.17it/s]\u001b[A\n",
      " 25%|██▌       | 2/8 [00:00<00:02,  2.11it/s]\u001b[A\n",
      " 38%|███▊      | 3/8 [00:01<00:02,  2.06it/s]\u001b[A\n",
      " 50%|█████     | 4/8 [00:02<00:02,  1.97it/s]\u001b[A\n",
      "Epoch:   0%|          | 0/20 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-28e95fedc542>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# unpacking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1105\u001b[0m                 fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1108\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m             \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/virtualenvs/cs230/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/virtualenvs/cs230/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/virtualenvs/cs230/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/virtualenvs/cs230/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Stanford/CS 230 - Deep Learning/Project/linguistic-style-transfer-pytorch/linguistic_style_transfer_pytorch/data_loader.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel2index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sentence_tokenid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mbow_rep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_bow_representations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbow_rep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Stanford/CS 230 - Deep Learning/Project/linguistic-style-transfer-pytorch/linguistic_style_transfer_pytorch/data_loader.py\u001b[0m in \u001b[0;36m_get_bow_representations\u001b[0;34m(self, text_sequence)\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0msequence_bow_representation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbow_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         sequence_bow_representation /= np.max(\n\u001b[0;32m---> 66\u001b[0;31m             [np.sum(sequence_bow_representation), 1])\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_bow_representation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mamax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2666\u001b[0m     \"\"\"\n\u001b[1;32m   2667\u001b[0m     return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n\u001b[0;32m-> 2668\u001b[0;31m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0m\u001b[1;32m   2669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from linguistic_style_transfer_pytorch.config import GeneralConfig, ModelConfig\n",
    "from linguistic_style_transfer_pytorch.data_loader import TextDataset\n",
    "from linguistic_style_transfer_pytorch.model import AdversarialVAE\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "use_cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "\n",
    "\n",
    "mconfig = ModelConfig()\n",
    "gconfig = GeneralConfig()\n",
    "weights = torch.FloatTensor(np.load(gconfig.word_embedding_path))\n",
    "# load word embeddings\n",
    "weights = torch.FloatTensor(np.load(gconfig.word_embedding_path))\n",
    "# load checkpoint\n",
    "model_checkpoint = torch.load('linguistic_style_transfer_pytorch/checkpoints/model_epoch_20.pt')\n",
    "# Load model\n",
    "model = AdversarialVAE(weight=weights)\n",
    "model.load_state_dict(model_checkpoint)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "#=============== Define dataloader ================#\n",
    "test_dataset = TextDataset(mode='test')\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=mconfig.batch_size)\n",
    "#content_discriminator_params, style_discriminator_params, vae_and_classifier_params = model.get_params()\n",
    "#============== Define optimizers ================#\n",
    "\n",
    "\n",
    "for epoch in trange(mconfig.epochs, desc=\"Epoch\"):\n",
    "\n",
    "    for iteration, batch in enumerate(tqdm(test_dataloader)):\n",
    "    \n",
    "        # unpacking\n",
    "        sequences, seq_lens, labels, bow_rep = batch\n",
    "        if use_cuda:\n",
    "            sequences = sequences.cuda()\n",
    "            seq_lens = seq_lens.cuda()\n",
    "            labels = labels.cuda()\n",
    "            bow_rep = bow_rep.cuda()\n",
    "        content_disc_loss, style_disc_loss, vae_and_cls_loss = model(\n",
    "            sequences, seq_lens.squeeze(1), labels, bow_rep, iteration+1, epoch == mconfig.epochs-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def transfer_style(self, sequence, style):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sequence : token indices of input sentence of shape = (random_seq_length,)\n",
    "            style: target style\n",
    "        Returns:\n",
    "            transfered_sentence: token indices of style transfered sentence, shape=(random_seq_length,)\n",
    "        \"\"\"\n",
    "        # pack the sequences to reduce unnecessary computations\n",
    "        # It requires the sentences to be sorted in descending order to take\n",
    "        # full advantage\n",
    "        import ipdb; ipdb.set_trace()\n",
    "        embedded_seqs = self.embedding(sequence.unsqueeze(0))\n",
    "        # output, final_hidden_state = self.encoder(embedded_seq)\n",
    "\n",
    "        seq_lengths = torch.from_numpy(np.array([4]))\n",
    "        packed_seqs = pack_padded_sequence(\n",
    "            embedded_seqs, lengths=seq_lengths, batch_first=True)\n",
    "        packed_output, (_) = self.encoder(packed_seqs)\n",
    "        output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "        sentence_emb = output[torch.arange(output.size(0)), seq_lengths-1]\n",
    "        \n",
    "        # get content embeddings\n",
    "        # Note that we need not calculate style embeddings since we\n",
    "        # use the target style embedding\n",
    "        content_emb_mu, content_emb_log_var = self.get_content_emb(\n",
    "            sentence_emb)\n",
    "        # sample content embeddings latent space\n",
    "        sampled_content_emb = self.sample_prior(\n",
    "            content_emb_mu, content_emb_log_var)\n",
    "        # Get the approximate estimate of the target style embedding\n",
    "        target_style_emb = self.avg_style_emb[1]\n",
    "        # Generative embedding\n",
    "        generative_emb = torch.cat(\n",
    "            (target_style_emb, sampled_content_emb), axis=1)\n",
    "        # Generate the style transfered sentences\n",
    "        transfered_sentence = self.generate_sentences(\n",
    "            input_sentencs=None, latent_emb=generative_emb, inference=True)\n",
    "\n",
    "        return transfered_sentence.view(-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
